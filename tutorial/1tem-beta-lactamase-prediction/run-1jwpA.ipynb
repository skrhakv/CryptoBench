{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the structure and pocket\n",
    "For the **1jwpA** apo structure, the pocket annotation was identified using [AHoJ-DB](https://apoholo.cz/db/) by comparing it to its holo counterpart, the [1fqgA](https://apoholo.cz/db/entry/1fqg-A-PNM-523) structure. You can download the results and find the pocket selection there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_id = '1jwp'\n",
    "chain_id = 'A'\n",
    "pocket = 'A_69 A_70 A_73 A_105 A_130 A_132 A_170 A_216 A_234 A_235 A_236 A_237 A_238 A_240 A_244 A_272'\n",
    "pocket = [int(i.split('_')[1]) for i in pocket.split(' ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the sequence and binding indices within the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import biotite.database.rcsb as rcsb\n",
    "import biotite.structure.io.pdbx as pdbx\n",
    "from biotite.structure.io.pdbx import get_structure\n",
    "from biotite.sequence import ProteinSequence\n",
    "import numpy as np\n",
    "\n",
    "CIF_FILES_PATH = '/home/vit/Projects/deeplife-project/data/cif_files'\n",
    "\n",
    "cif_file_path = rcsb.fetch(pdb_id, \"cif\", CIF_FILES_PATH)\n",
    "cif_file = pdbx.CIFFile.read(cif_file_path)\n",
    "\n",
    "protein = get_structure(cif_file, model=1)\n",
    "protein = protein[(protein.atom_name == \"CA\") \n",
    "                       & (protein.element == \"C\") \n",
    "                       & (protein.chain_id == chain_id) ]\n",
    "\n",
    "sequence = ''.join([ProteinSequence.convert_letter_3to1(residue.res_name) for residue in protein])\n",
    "binding_indices = [f'{residue.chain_id}_{ProteinSequence.convert_letter_3to1(residue.res_name)}{i}' for i, residue in enumerate(protein) if residue.res_id in pocket]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the annotation and sequence files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(binding_indices) == len(pocket)\n",
    "\n",
    "with open(f'{pdb_id}{chain_id}.txt', 'w') as f:\n",
    "    f.write(sequence)\n",
    "\n",
    "with open(f'annotation.txt', 'w') as f:\n",
    "    f.write(f'{pdb_id};{chain_id};UNK;{\" \".join(binding_indices)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚠️ CAUTION: ESM2-3B Embedding computation required!\n",
    "For optimal performance, use a **GPU-equipped machine** when computing ESM2-3B embeddings, especially if processing multiple structures. While computation on a CPU-only machine should be possible, I haven't tested it. \n",
    "\n",
    "*Note: Computation of the ESM2 embedding is not part of this script. To generate embeddings, you may find [this script](https://github.com/skrhakv/esm2-generator/blob/master/compute-esm.py) in the [esm2-generator repository](https://github.com/skrhakv/esm2-generator) useful.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Run the prediction and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CryptoBench model ...\n",
      "Loading data - embeddings and annotations ...\n",
      "Making prediction ...\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "\n",
      "\n",
      "\n",
      "Evaluation for 1jwpA with decision threshold = 0.95:\n",
      "\n",
      "AUC: 0.9375\n",
      "AUPRC: 0.6728923909788846\n",
      "ACC: 0.9391634980988594\n",
      "TPR: 0.0\n",
      "FPR: 0.0\n",
      "MCC: 0.0\n",
      "F1: 0.9686274509803922\n"
     ]
    }
   ],
   "source": [
    "# This script is similar to the script provided in the CryptoBench dataset repository (https://osf.io/pz4a9/).\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "import sys\n",
    "\n",
    "# CAUTION: You need to specify the path to the CryptoBench dataset! It is available at: https://osf.io/pz4a9/\n",
    "CRYPTOBENCH_PATH = '/path/to/cryptobench'\n",
    "sys.path.append(f'{CRYPTOBENCH_PATH}/scripts')\n",
    "from Protein import Protein\n",
    "\n",
    "MODEL_PATH = f'{CRYPTOBENCH_PATH}/benchmark/best_trained'\n",
    "STRUCTURE_ID = f'{pdb_id}{chain_id}'\n",
    "\n",
    "# 0.95 decision threshold was used in the CryptoBench paper\n",
    "DECISION_THRESHOLD = 0.95\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    print(\"Loading CryptoBench model ...\")\n",
    "    return keras.models.load_model(MODEL_PATH,\n",
    "                                   custom_objects={\n",
    "                                       'MatthewsCorrelationCoefficient': tfa.metrics.MatthewsCorrelationCoefficient(num_classes=2)},\n",
    "                                   compile=False)\n",
    "\n",
    "\n",
    "def predict(X, model):\n",
    "    print(\"Making prediction ...\")\n",
    "    return model.predict(X)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    print(\"Loading data - embeddings and annotations ...\")\n",
    "    embeddings = np.load(f'{STRUCTURE_ID}.npy')\n",
    "\n",
    "    with open('annotation.txt', 'r') as f:\n",
    "        annotations = f.read().split(';')[3].split(' ')\n",
    "\n",
    "    # the format of each annotation is as follows: \n",
    "    # 'A_G210' denotes a single binding residue, which belongs to the 'A' chain,\n",
    "    # 'G' denotes that the residue is Glycine, and the corresponding embedding\n",
    "    # can be found at index 210 in the embeddings array\n",
    "    annotations = [int(i.split('_')[1][1:]) for i in annotations]\n",
    "    y = [0] * embeddings.shape[0]\n",
    "    for ix in annotations:\n",
    "        y[ix] = 1\n",
    "\n",
    "    return embeddings, y\n",
    "\n",
    "\n",
    "def print_evaluation(evaluation):\n",
    "    print(\n",
    "        f'\\n\\n\\nEvaluation for {evaluation.id} with decision threshold = {DECISION_THRESHOLD}:\\n')\n",
    "    print(f'AUC: {evaluation.auc}')\n",
    "    print(f'AUPRC: {evaluation.auprc}')\n",
    "    print(f'ACC: {evaluation.accuracy}')\n",
    "    print(f'TPR: {evaluation.get_TPR()}')\n",
    "    print(f'FPR: {evaluation.get_FPR()}')\n",
    "    print(f'MCC: {evaluation.mcc}')\n",
    "    print(f'F1: {evaluation.f1}')\n",
    "\n",
    "\n",
    "def evaluate(prediction, actual):\n",
    "    evaluation = Protein(STRUCTURE_ID, prediction, actual,\n",
    "                         threshold=DECISION_THRESHOLD)\n",
    "    print_evaluation(evaluation)\n",
    "    return evaluation\n",
    "\n",
    "model = load_model()\n",
    "embeddings, annotations = load_data()\n",
    "predictions = predict(embeddings, model)\n",
    "evaluation = evaluate(predictions, annotations)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
